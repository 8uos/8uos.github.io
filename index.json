[{"authors":null,"categories":null,"content":"I am interested in interpreting and understanding visual concepts with multiple view points (e.g., mood, emotion, style, texture) to extract better visual representations for real-world downstream tasks.\nDownload my curriculum vitae.\n","date":1625097600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1625097600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://example.org/author/song-park/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/song-park/","section":"authors","summary":"I am interested in interpreting and understanding visual concepts with multiple view points (e.g., mood, emotion, style, texture) to extract better visual representations for real-world downstream tasks.\nDownload my curriculum vitae.","tags":null,"title":"Song Park","type":"authors"},{"authors":["Song Park","Sanghyuk Chun","Junbum Cha","Bado Lee","Hyunjung Shim"],"categories":null,"content":"","date":1625097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1625097600,"objectID":"f610f5569f82050ec0ad3d4ba434de7d","permalink":"http://example.org/publication/mx-font/","publishdate":"2021-07-01T00:00:00Z","relpermalink":"/publication/mx-font/","section":"publication","summary":"A few-shot font generation (FFG) method has to satisfy two objectives: the generated images should preserve the underlying global structure of the target character and present the diverse local reference style. Existing FFG methods aim to disentangle content and style either by extracting a universal representation style or extracting multiple component-wise style representations. However, previous methods either fail to capture diverse local styles or cannot be generalized to a character with unseen components, e.g., unseen language systems. To mitigate the issues, we propose a novel FFG method, named Multiple Localized Experts Few-shot Font Generation Network (MX-Font). MX-Font extracts multiple style features not explicitly conditioned on component labels, but automatically by multiple experts to represent different local concepts, e.g., left-side sub-glyph. Owing to the multiple experts, MX-Font can capture diverse local concepts and show the generalizability to unseen languages. During training, we utilize component labels as weak supervision to guide each expert to be specialized for different local concepts. We formulate the component assign problem to each expert as the graph matching problem, and solve it by the Hungarian algorithm. We also employ the independence loss and the content-style adversarial loss to impose the content-style disentanglement. In our experiments, MX-Font outperforms previous state-of-the-art FFG methods in the Chinese generation and cross-lingual, e.g., Chinese to Korean, generation.","tags":["Few-shot Font Generation","Image to Image Translation"],"title":"Multiple Heads are Better than One: Few-shot Font Generation with Multiple Localized Experts","type":"publication"},{"authors":["Song Park","Sanghyuk Chun","Junbum Cha","Bado Lee","Hyunjung Shim"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"2ecd96dae33db0040892747a4c6b5cad","permalink":"http://example.org/publication/lf-font/","publishdate":"2021-02-01T00:00:00Z","relpermalink":"/publication/lf-font/","section":"publication","summary":"Automatic few-shot font generation is in high demand because manual designs are expensive and sensitive to the expertise of designers. Existing methods of few-shot font generation aims to learn to disentangle the style and content element from a few reference glyphs and mainly focus on a universal style representation for each font style. However, such approach limits the model in representing diverse local styles, and thus make it unsuitable to the most complicated letter system, e.g., Chinese, whose characters consist of a varying number of components (often called 'radical') with a highly complex structure. In this paper, we propose a novel font generation method by learning localized styles, namely component-wise style representations, instead of universal styles. The proposed style representations enable us to synthesize complex local details in text designs. However, learning component-wise styles solely from reference glyphs is infeasible in the few-shot font generation scenario, when a target script has a large number of components, e.g., over 200 for Chinese. To reduce the number of reference glyphs, we simplify component-wise styles by a product of component factor and style factor, inspired by low-rank matrix factorization. Thanks to the combination of strong representation and a compact factorization strategy, our method shows remarkably better few-shot font generation results (with only 8 reference glyph images) than other state-of-the-arts, without utilizing strong locality supervision, e.g., location of each component, skeleton, or strokes.","tags":["Few-shot Font Generation","Image to Image Translation"],"title":"Few-shot Font Generation with Localized Style Representations and Factorization","type":"publication"},{"authors":["Joo Hyun Park","Song Park"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"078a285c7898263d72c082d808aad740","permalink":"http://example.org/publication/semantic-aware/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/semantic-aware/","section":"publication","summary":"This study proposes a semantic-aware style transfer method for resolving semantic mismatch problems in existing algorithms. As the primary focus of this study, the consideration of semantic matching is expected to improve the quality of artistic style transfer. Here, each image is partitioned into several semantic regions for both a target photograph and a source painting. All partitioned regions of the target are then associated with one of the partitioned regions in the source according to their semantic interpretation. Given a pair of target and source regions, style is learned from the source region whereas content is learned from the target region. By integrating both the style and content components, we can successfully generate a stylized output. Unlike previous approaches, we obtain the best semantic match between regions using word embeddings. Thus, we guarantee that semantic matching is always established between the target and source. Moreover, it is unreliable to partition a painting using existing algorithms because of statistical gaps between the real photographs and paintings. To bridge such gaps, we apply a domain adaptation technique on the source painting to extract its semantic regions. We evaluated the effectiveness of the proposed algorithm based on a thorough experimental analysis and comparison. Through a user study, it is confirmed that semantic information considerably influences the quality assessment of style transfer.","tags":["Style Transfer"],"title":"Semantic-aware Neural Style Transfer","type":"publication"},{"authors":["Junsuk Choe","Song Park","Kyungmin Kim","Joo Hyun Park","Dongseob Kim","Hyunjung Shim"],"categories":null,"content":"","date":1498867200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1498867200,"objectID":"c5b1b5838a69986a9af8fb11636aa3a7","permalink":"http://example.org/publication/facegan/","publishdate":"2017-07-01T00:00:00Z","relpermalink":"/publication/facegan/","section":"publication","summary":"Recently, low-shot learning has been proposed for handling the lack of training data in machine learning. Despite of the importance of this issue, relatively less efforts have been made to study this problem. In this paper, we aim to increase the size of training dataset in various ways to improve the accuracy and robustness of face recognition. In detail, we adapt a generator from the Generative Adversarial Network (GAN) to increase the size of training dataset, which includes a base set, a widely available dataset, and a novel set, a given limited dataset, while adopting transfer learning as a backend. Based on extensive experimental study, we conduct the analysis on various data augmentation methods, observing how each affects the identification accuracy. Finally, we conclude that the proposed algorithm for generating faces is effective in improving the identification accuracy and coverage at the precision of 99% using both the base and novel set.","tags":["Face Generation","Low-shot Learning"],"title":"Face generation for low-shot learning using generative adversarial networks","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"http://example.org/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]